{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import shapely\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rsutils.modify_images\n",
    "import rsutils.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION_SHAPEFILEPATH = '/gpfs/data1/cmongp2/sasirajann/nh_crop_calendar/crop_calendar/data/shapefiles/AfSP012Qry_ISRIC/GIS_Shape/AfSP012Qry_SubSaharanAfrica.shp'\n",
    "WEATHER_CATALOG_FILEPATH = '/gpfs/data1/cmongp2/sasirajann/nh_crop_calendar/crop_calendar/data/weather_catalog_1994-2025.csv'\n",
    "REFERENCE_TIF_FILEPATH = '/gpfs/data1/cmongp2/sasirajann/nh_crop_calendar/crop_calendar/data/ref_mod09.ndvi.global_0.05_degree.2019.001.c6.v1.tif'\n",
    "\n",
    "NJOBS = 120\n",
    "\n",
    "REGION = 'sub-saharan-africa'\n",
    "\n",
    "OUTPUT_FOLDERPATH = f'/gpfs/data1/cmongp2/sasirajann/nh_crop_calendar/crop_calendar/data/outputs/{REGION}'\n",
    "\n",
    "os.makedirs(OUTPUT_FOLDERPATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_attribute_datacube(\n",
    "    catalog_df:pd.DataFrame,\n",
    "    region_gdf:gpd.GeoDataFrame,\n",
    "    export_filepath:str,\n",
    "):\n",
    "    try:\n",
    "        catalog_df['date'].dt\n",
    "    except:\n",
    "        raise ValueError(\"'date' column in catalog_df is not of datetype\")\n",
    "    \n",
    "    catalog_df = catalog_df.sort_values(by='date')\n",
    "\n",
    "    data_profile_list = rsutils.modify_images.load_images(\n",
    "        src_filepaths = catalog_df['tif_filepath'],\n",
    "        shapes_gdf = region_gdf,\n",
    "        njobs = NJOBS,\n",
    "        raise_error = False,\n",
    "    )\n",
    "\n",
    "    catalog_df['to_drop'] = [data is None for data, _ in data_profile_list]\n",
    "    catalog_df = catalog_df[~catalog_df['to_drop']]\n",
    "\n",
    "    data_profile_list = [(data, profile) for data, profile in data_profile_list if data is not None]\n",
    "\n",
    "    data_profile_list = rsutils.modify_images.modify_images_inplace(\n",
    "        data_profile_list = data_profile_list,\n",
    "        njobs = NJOBS,\n",
    "        sequence = [\n",
    "            (rsutils.modify_images.resample_by_ref, dict(ref_filepath=REFERENCE_TIF_FILEPATH)),\n",
    "            (rsutils.modify_images.crop, dict(shapes_gdf=region_gdf, all_touched=True)),\n",
    "        ],\n",
    "        raise_error = True,\n",
    "    )\n",
    "\n",
    "    nparray = np.concatenate([data for data, _ in data_profile_list], axis=0)\n",
    "    \n",
    "    if nparray.dtype == np.uint8:\n",
    "        nparray = nparray.astype(np.int16)\n",
    "\n",
    "    dataarray = xr.DataArray(\n",
    "        data = nparray,\n",
    "        dims = ('timestamps', 'height', 'width'),\n",
    "        coords = {\n",
    "            'timestamps': catalog_df['date'].to_list(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    dataarray.to_netcdf(export_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_gdf = gpd.read_file(REGION_SHAPEFILEPATH)\n",
    "\n",
    "region_gdf.to_file(os.path.join(OUTPUT_FOLDERPATH, f'{REGION}.geojson'))\n",
    "\n",
    "weather_catalog_df = pd.read_csv(WEATHER_CATALOG_FILEPATH)\n",
    "\n",
    "weather_catalog_df['date'] = weather_catalog_df['date'].apply(\n",
    "    lambda x: datetime.datetime.strptime(x, '%Y-%m-%d')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapely.unary_union(region_gdf['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_catalog_df['attribute'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = weather_catalog_df['attribute'].unique().tolist()\n",
    "\n",
    "for attribute in tqdm.tqdm(attributes):\n",
    "    # if attribute in ['esi-4wk']:\n",
    "    #     print(f'Skipping attribute = {attribute}')\n",
    "    #     continue \n",
    "\n",
    "    print(f'Creating datacube for attribute = {attribute}')\n",
    "    export_filepath = os.path.join(OUTPUT_FOLDERPATH, f'{attribute}.nc')\n",
    "    \n",
    "    if os.path.exists(export_filepath):\n",
    "        print(f'Already exists.')\n",
    "        continue\n",
    "\n",
    "    create_attribute_datacube(\n",
    "        catalog_df = weather_catalog_df[\n",
    "            weather_catalog_df['attribute'] == attribute\n",
    "        ],\n",
    "        region_gdf = region_gdf,\n",
    "        export_filepath = export_filepath,\n",
    "    )\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    print(f'Created !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nh_crop_calendar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
